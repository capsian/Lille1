<!doctype html>
<html lang="fr">
<head>
<title>Variables aléatoires, espérance et analyse du tri rapide (quicksort)</title>
<!-- 2021-03-23 mar. 09:47 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="generator" content="Org-mode">
<meta name="author" content="Sylvain Salvati">

<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>
<style>
/* org mode styles on top of twbs */

html {
    position: relative;
    min-height: 100%;
}

body {
    font-size: 18px;
    margin-bottom: 105px;
}

footer {
    position: absolute;
    bottom: 0;
    width: 100%;
    height: 101px;
    background-color: #f5f5f5;
}

footer > div {
    padding: 10px;
}

footer p {
    margin: 0 0 5px;
    text-align: center;
    font-size: 16px;
}

#table-of-contents {
    margin-top: 20px;
    margin-bottom: 20px;
}

blockquote p {
    font-size: 18px;
}

pre {
    font-size: 16px;
}

.footpara {
    display: inline-block;
}

figcaption {
  font-size: 16px;
  color: #666;
  font-style: italic;
  padding-bottom: 15px;
}

/* from twbs docs */

.bs-docs-sidebar.affix {
    position: static;
}
@media (min-width: 768px) {
    .bs-docs-sidebar {
        padding-left: 20px;
    }
}

/* All levels of nav */
.bs-docs-sidebar .nav > li > a {
    display: block;
    padding: 4px 20px;
    font-size: 14px;
    font-weight: 500;
    color: #999;
}
.bs-docs-sidebar .nav > li > a:hover,
.bs-docs-sidebar .nav > li > a:focus {
    padding-left: 19px;
    color: #A1283B;
    text-decoration: none;
    background-color: transparent;
    border-left: 1px solid #A1283B;
}
.bs-docs-sidebar .nav > .active > a,
.bs-docs-sidebar .nav > .active:hover > a,
.bs-docs-sidebar .nav > .active:focus > a {
    padding-left: 18px;
    font-weight: bold;
    color: #A1283B;
    background-color: transparent;
    border-left: 2px solid #A1283B;
}

/* Nav: second level (shown on .active) */
.bs-docs-sidebar .nav .nav {
    display: none; /* Hide by default, but at >768px, show it */
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 30px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav > li > a:focus {
    padding-left: 29px;
}
.bs-docs-sidebar .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav > .active:focus > a {
    padding-left: 28px;
    font-weight: 500;
}

/* Nav: third level (shown on .active) */
.bs-docs-sidebar .nav .nav .nav {
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 40px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav .nav > li > a:focus {
    padding-left: 39px;
}
.bs-docs-sidebar .nav .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav .nav > .active:focus > a {
    padding-left: 38px;
    font-weight: 500;
}

.code-highlighted { background-color: #ffff00; }

/* .verbatim { color: #3e9409;
            background-color: #f5fbf4; }*/
.verbatim {
    color: #337ab7;
    background-color: #d9edf7; }


/* Show and affix the side nav when space allows it */
@media (min-width: 992px) {
    .bs-docs-sidebar .nav > .active > ul {
        display: block;
    }
    /* Widen the fixed sidebar */
    .bs-docs-sidebar.affix,
    .bs-docs-sidebar.affix-bottom {
        width: 213px;
    }
    .bs-docs-sidebar.affix {
        position: fixed; /* Undo the static from mobile first approach */
        top: 20px;
    }
    .bs-docs-sidebar.affix-bottom {
        position: absolute; /* Undo the static from mobile first approach */
    }
    .bs-docs-sidebar.affix .bs-docs-sidenav,.bs-docs-sidebar.affix-bottom .bs-docs-sidenav {
        margin-top: 0;
        margin-bottom: 0
    }
}
@media (min-width: 1200px) {
    /* Widen the fixed sidebar again */
    .bs-docs-sidebar.affix-bottom,
    .bs-docs-sidebar.affix {
        width: 263px;
    }
}
</style>
<style>body { margin-bottom: 0px; }</style><script>
$(function() {
    'use strict';

    $('.bs-docs-sidebar li').first().addClass('active');

    $(document.body).scrollspy({target: '.bs-docs-sidebar'});

    $('.bs-docs-sidebar').affix();
});
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }

</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  displayAlign: "center",
  displayIndent: "2em",
  messageStyle: "none",
  "HTML-CSS": {
    scale: 100,
    styles: {
      ".MathJax_Display": {
        "font-size": "100%"
      }
    }
  },
  "SVG": {
    scale: 100,
    styles: {
      ".MathJax_SVG_Display": {
        "font-size": "100%",
        "margin-left": "-2.281em"
      }
    }
  }
});
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"></script>
</head>
<body>
<div id="content" class="container">
<div class="row"><div class="col-md-3 col-md-push-9"><nav id="table-of-contents">
<div id="text-table-of-contents" class="bs-docs-sidebar">
<ul class="nav">
<li><a href="#sec-1">1. Variables aléatoires de Bernoulli et variables aléatoires binomiales</a></li>
<li><a href="#sec-2">2. Espérance conditionnelle</a>
<ul class="nav">
<li><a href="#sec-2-1">2.1. Exercice</a></li>
</ul>
</li>
<li><a href="#sec-3">3. La distribution géométrique</a>
<ul class="nav">
<li><a href="#sec-3-1">3.1. Exercice</a></li>
</ul>
</li>
<li><a href="#sec-4">4. Tri rapide</a></li>
</ul>
</div>
</nav>
</div><div class="col-md-9 col-md-pull-3"><h1 class="title">Variables aléatoires, espérance et analyse du tri rapide (quicksort)</h1>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Variables aléatoires de Bernoulli et variables aléatoires binomiales</h2>
<div class="outline-text-2" id="text-1">
<p>
Une variable aléatoire de <i>Bernoulli</i> ne prend que deux valeurs 0 et 1. Ainsi,
lorsque X est une variable de Bernoulli, Pr(X = 1) = p et Pr(X = 0) = 1-p. De
plus, E(X) = p*1 + (1-p)*0 = p. = Pr(X = 1).
</p>

<p>
Par exemple, la variable aléatoire qui indique que "pile" est tiré lors du
lancé d'une pièce est une variable de Bernoulli, d'espérance 1/2 (lorsque la
pièce est équilibrée).
</p>

<p>
Si on considère une séquence de n lancés de pièce, quelle est alors la
distribution du nombre de fois que "pile" est tiré. Plus généralement
qu'arrive-t-il lorsque l'on itère n expériences qui ont une probabilité p de
réussir ?
</p>

<p>
Si X représente le nombre de succès de ces n expériences, alors X suit une
<i>loi binomiale</i>.
</p>

<p>
Une loi binomiale est une variable aléatoire dotée de deux paramètres n et p :
</p>
<ul class="org-ul">
<li>n est le nombre d'expériences
</li>
<li>p est la probabilité de succès de ces expériences.
</li>
</ul>
<p>
On note B(n,p) cette loi. Elle suit la distribution de probabilité suivante
(j ∈ {0,&#x2026;,n}:
\[Pr(X = j) = C^j_n p^j (1-p)^{n-j}\]
</p>

<p>
Remarquez que :
\[\sum_{j=0}^n C^j_n p^j (1-p)^{n-j} = (p+(1-p))^n = 1^n = 1\]
</p>

<p>
La loi binomiale apparaît très fréquemment lorsque l'on utilise une méthode de
<i>sampling</i>.
</p>


<p>
L'espérance de la loi binomiale est (X est une variable aléatoire suivant la
loi binomiale) :
</p>

<p>
\[\begin{array}{rcl}
    E(X)& = & \sum_{j=0}^nj C^j_n p^j (1-p)^{n-j}\\
        & = & \sum_{j=0}^n j \frac{n!}{j!(n-j)!} p^j (1-p)^{n-j}\\
        & = & \sum_{j=1}^n \frac{n!}{(j-1)!(n-j)!} p^j (1-p)^{n-j}\\
        & = & np\sum_{j=1}^n \frac{(n-1)!}{(j-1)!((n-1)-(j-1))!} p^{j-1}
              (1-p)^{(n-1)-(j-1)}\\
        & = & np\sum_{k=0}^{n-1} \frac{(n-1)!}{k!((n-1)-k)!} p^{k}
              (1-p)^{(n-1)-k}\\
        & = & np\sum_{k=0}^{n-1} C^k_{n-1} p^{k}
              (1-p)^{(n-1)-k}\\
        &=&np
  \end{array}\]
</p>

<p>
On peut également obtenir ce résultat de manière plus élégante en décomposant
une variable binomiale de loi B(n,p) comme n variables aléatoires de Bernoulli
X<sub>1</sub>, &#x2026;, X<sub>n</sub>. Alors nous avons, \(X = \sum_{i=1}^n X_i\). En utilisant la
linéarité de l'espérance nous obtenons :
\[E(X) = E\left(\sum_{i=1}^n X_i \right) = \sum_{i=1}^nE(X_i) = np\]
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Espérance conditionnelle</h2>
<div class="outline-text-2" id="text-2">
<p>
L'espérance conditionnelle d'une variable aléatoire Y sachant que Z = z est :
\[E(Y | Z = z)  = \sum_y y Pr(Y=y\mid Z = z)\]
</p>

<p>
Si X et Y sont des variables aléatoires, nous avons :
</p>

<p>
\[E(X) = \sum_y Pr(Y=y) E(X |Y=y)\]
</p>

<p>
En effet :
\[\begin{array}{rcl}
      \sum_y Pr(Y=y) E(X |Y=y)
      & = & \sum_y Pr(Y=y) \sum_x x Pr(X=x |Y=y)\\
      & = & \sum_y \sum_x x Pr(X=x |Y=y) Pr(Y=y)\\
      & = & \sum_y \sum_x x Pr(X=x \cap Y=y)\\
      & = & \sum_x \sum_y x Pr(X=x \cap Y=y)\\
      & = & \sum_x x Pr(X=x)\\
      & = & E(X)
    \end{array} \]
</p>

<p>
De plus l'espérance conditionnelle est linéaire:
\[E\left(\left(\sum_{i=1}^n X_i\right) \mid Y = y\right) = \sum_{i=1}^n E(X_i
  \mid Y= y)\]
</p>

<p>
Finalement on note E(Y | Z) la variable aléatoire f(Z) qui prend pour
valeur E(Y | Z = z) lorsque Z = z.
</p>

<p>
<b><b>NB :</b></b> E(Y | Z) n'est pas une valeur, mais une <b><b>variable aléatoire</b></b>.
</p>

<p>
De plus, \(E(Y) = E(E(Y \mid Z))\) en effet, par ce qui précède, 
\[E(E(Y\mid Z)) = \sum_{z} E(Y \mid Z=z)Pr(Z = z) = E(Y)\]
</p>
</div>



<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Exercice</h3>
<div class="outline-text-3" id="text-2-1">
</div><div id="outline-container-sec-2-1-1" class="outline-4">
<h4 id="sec-2-1-1"><span class="section-number-4">2.1.1</span> Jets de dés</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
Si X est la variable aléatoire qui est la somme réalisée par le jet de deux
dés à six faces. Si X<sub>1</sub> et X<sub>2</sub> sont les variables aléatoires correspondant
aux valeurs obtenues par chacun des dés.
</p>
</div>
<ol class="org-ol"><li><a id="sec-2-1-1-1" name="sec-2-1-1-1"></a>Question 1<br ><div class="outline-text-5" id="text-2-1-1-1">
<p>
Calculer E(X | X<sub>1</sub> = 2)
</p>
</div>
</li>
<li><a id="sec-2-1-1-2" name="sec-2-1-1-2"></a>Question 2<br ><div class="outline-text-5" id="text-2-1-1-2">
<p>
Calculer E(X<sub>1</sub> | X = 5)
</p>
</div>
</li></ol>
</div>
<div id="outline-container-sec-2-1-2" class="outline-4">
<h4 id="sec-2-1-2"><span class="section-number-4">2.1.2</span> Réplication de bactéries</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
Une bactérie suit une loi binomiale B(n,p) pour sa réplication. Chacune de
ses descendantes suit la même loi de réplication. Pour analyser le nombre
moyen d'une colonie après i générations, on appelle Y<sub>i</sub> la variable
aléatoire correspondant au nombre de bactérie de la ième génération. On
considère que la colonisation bactérienne commence avec une seule bactérie
et que Y<sub>0</sub> = 1.
</p>
</div>
<ol class="org-ol"><li><a id="sec-2-1-2-1" name="sec-2-1-2-1"></a>Question 1<br ><div class="outline-text-5" id="text-2-1-2-1">
<p>
Calculer l'espérance \(E(Y_i \mid Y_{i-1}=y_{i-1})\)
</p>
</div>
</li>
<li><a id="sec-2-1-2-2" name="sec-2-1-2-2"></a>Question 2<br ><div class="outline-text-5" id="text-2-1-2-2">
<p>
En déduire l'espérance \(E(Y_i)\).
</p>
</div>
</li></ol>
</div>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> La distribution géométrique</h2>
<div class="outline-text-2" id="text-3">
<p>
Supposons que nous lancions une pièce jusqu'à ce qu'elle tombe sur "pile". On
appelle <i>distribution géométrique</i> la distribution du nombre de lancé réalisé
par ce genre d'expérience où on effectue une séquence d'essais indépendants
jusqu'à la réussite (qui a une probabilité p).
</p>

<p>
Si X est une variable aléatoire géométrique (i.e. suivant une distribution
géométrique) alors pour tout n:
\[Pr(X = n) = (1-p)^{n-1} p\]
</p>


<p>
On remarque que l'on a bien \(\sum_{n\geq 1} Pr(X = n) = 1\) :
\[\begin{array}{rcl}
      \sum_{n\geq 1} Pr(X = n)
      & = &\sum_{n\geq 1} (1-p)^{n-1} p\\
      & = &p \sum_{n\geq 1} (1-p)^{n-1}\\
      & = &p \sum_{m\geq 0} (1-p)^{m}\\
      & = & p \frac{1}{1 - (1-p)} \\
      & = & \frac{p}{p}\\
      & = & 1\\
    \end{array}\]
</p>

<p>
Les variables aléatoires géométriques sont dites sans mémoire car à chaque
nouvelle expérience, la probabilité de succès est invariante. Ainsi, pour tout
variable aléatoire géométrique de paramètre p  et n &gt; 0,
\[Pr(X = n+k \mid X > k) = Pr(X = n)\]
</p>

<p>
De plus,
\[Pr(X \geq i) = \sum_{n\geq i} (1-p)^{n-1} p = (1-p)^{i-1}\]
</p>

<p>
Ainsi
\[\begin{array}{rcl}
      E(X)
      & = & \sum_{j\geq 1}j Pr(X=j)\\
      & = & \sum_{j\geq 1}\sum_{i=1}^j Pr(X=j)\\
      & = & \sum_{i\geq 1}\sum_{j\geq i} Pr(X=j)\\
      & = & \sum_{i\geq 1}Pr(X\geq j)\\
      & = & \sum_{i\geq 1}(1-p)^{i-1}\\
      & = & \frac{1}{1-(1-p)}\\
      & = & \frac{1}{p}
    \end{array}\]
</p>

<p>
On peut également calculer l'espérance de X en utilisant l'espérance
conditionnelle. Si on appelle Y la variable aléatoire de Bernoulli qui indique
si l'expérience réussit, nous avons:
\[\begin{array}{rcl}
  E(X) &=& Pr(Y=0)E(X \mid Y=0) + Pr(Y = 1) E(X \mid Y = 1)\\
  &=& (1-p)E(X \mid Y=0) + pE(X \mid Y = 1)\\
  \end{array}\]
Si Y = 1 alors X = 1 et E(X | Y = 1) = 1. Si Y = 0, alors X &gt; 1. Dans ce cas,
on appelle Z le nombre d'essai à suivre. Par linéarité de l'espérance :
\[E(X) = (1-p)E(Z + 1) + p = (1-p)E(Z)+1\]
Comme les variables aléatoires géométriques sont sans mémoire E(Z) = E(X) et
il s'ensuit que E(X) = 1/p.
</p>
</div>

<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Exercice</h3>
<div class="outline-text-3" id="text-3-1">
</div><div id="outline-container-sec-3-1-1" class="outline-4">
<h4 id="sec-3-1-1"><span class="section-number-4">3.1.1</span> Nombre moyen de tour de boucle</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
Donner le nombre moyen de tours de boucle effectuer par l'algorithme
<code>_randbelow_with_getrandbits</code> de la librairie <a href="https://github.com/python/cpython/blob/0554044ddccdb7bf1fa4a8bc880e7a7b59f6479c/Lib/random.py#L240"><code>random</code> de python</a>.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-2" class="outline-4">
<h4 id="sec-3-1-2"><span class="section-number-4">3.1.2</span> Le problème du collectionneur de coupons</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
Pour fidéliser ses clients une marque de céréale propose à ces clients de
trouver n coupons différents dans les boîtes qu'elle met en vente. Un client
ayant trouvé les n coupons remporte un prix. Si on suppose que les n coupons
apparaissent avec la même probabilité dans les boîtes, on cherche à évaluer
le nombre moyen de boîtes qu'un client doit acheter pour gagner un prix.
</p>
</div>
<ol class="org-ol"><li><a id="sec-3-1-2-1" name="sec-3-1-2-1"></a>Question 1<br ><div class="outline-text-5" id="text-3-1-2-1">
<p>
On appelle X<sub>i</sub> la variable aléatoire qui correspond au nombre de achetée
pour avoir un nouveau coupons alors que l'on possède déjà i-1 coupons
différents. X<sub>i</sub> est une variable aléatoire géométrique. Donner :
</p>
<ol class="org-ol">
<li>sa probabilité de succès,
</li>
<li>son espérance.
</li>
</ol>
</div>
</li>
<li><a id="sec-3-1-2-2" name="sec-3-1-2-2"></a>Question 2<br ><div class="outline-text-5" id="text-3-1-2-2">
<p>
Calculer l'espérance de la variable X du nombre de boîte achetée pour avoir
tous les coupons.
</p>

<p>
<b><b>NB :</b></b> \(\sum_{i=1}^n1/i\) est le nombre harmonique \(H(n)\) et \(H(n) =
     \ln(n) + \Theta(1)\).
</p>
</div>
</li></ol>
</div>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Tri rapide</h2>
<div class="outline-text-2" id="text-4">
<p>
L'algorithme de tri rapide proposé par Hoare est un tri qui est très efficace.
Cependant, il a un temps d'exécution dans le pire cas qui est en
\(\mathcal{O}(n^2)\). L'une des raisons de son efficacité est qu'il peut être
implémenté en place, c'est-à-dire en utilisant une mémoire bornée (pour tout
tableau) en plus de celle qui contient le tableau à trier.
</p>

<p>
L'algorithme de tri rapide consiste :
</p>
<ol class="org-ol">
<li>à prendre un pivot (typiquement le premier élément du tableau),
</li>
<li>à déplacer en début de tableau tous les élements plus petits que le pivot,
</li>
<li>à déplacer en fin de tableau tous les élements plus grands que le pivot,
</li>
<li>appeler récursivement l'algorithme sur les parties du tableau avant et
après le pivot.
</li>
</ol>

<p>
Une méthode pour essayer de rendre cet algorithme efficace en toute
circonstance consiste à choisir le pivot aléatoirement (uniformément). On
espère ainsi éviter que l'algorithme se comporte mal sur certains tableaux.
</p>

<p>
Nous allons voir qu'en moyenne le tri rapide aléatoire s'exécute en effectuant
\(2n ln(n) + \Theta(n)\) comparaisons d'éléments du tableau initial (ce nombre de
comparaison est comparable au temps d'exécution).
</p>


<p>
Nous supposons  que nous avons à trier le tableau contenant (dans cet ordre)
les valeurs x<sub>1</sub>, x<sub>2</sub>, &#x2026;, x<sub>n</sub>. Supposons que y<sub>1</sub>, y<sub>2</sub>, &#x2026;, y<sub>n</sub> soient ces
mêmes valeurs prises dans l'ordre croissant. Pour i &lt; j, on appelle \(X_{ij}\)
la variable aléatoire qui vaut 1 si y<sub>i</sub> et y<sub>j</sub> sont comparée pendant
l'exécution de l'algorithme et 0 sinon.
</p>

<p>
Le nombre X de comparaisons est alors :
\[X = \sum_{i=1}^{n-1} \sum_{j =i+1}^n X_{ij}\]
</p>


<p>
Par linéarité de l'espérance, nous avons que \[E(X) = E\left(\sum_{i=1}^{n-1}
  \sum_{j =i+1}^n X_{ij}\right) = \sum_{i=1}^{n-1} \sum_{j =i+1}^n E(X_{ij})\]
</p>

<p>
Les variables X<sub>ij</sub> sont des variables aléatoire de Bernoulli. Il nous faut
ainsi calculer la probabilité Pr(X<sub>ij</sub>) = 1. Pour cela, on remarque que y<sub>i</sub>
et y<sub>j</sub> sont comparées ssi l'une ou l'autre est la première valeur choisie
comme pivot dans l'ensemble \(s_{ij} = \{y_i, y_{i+1}, ..., y_{j-1}, y_j\}\). En
effet, si une autre valeur est choisie, y<sub>i</sub> et y<sub>j</sub> se retrouve dans deux
parties différentes du tableau et ne seront pas comparées. Comme les pivots
sont choisis uniformément dans le tableau, la première fois qu'un pivot est
choisi dans \(s_{ij}\), chacun a la même probabilité d'être choisi. Ainsi la
probabilité que ce soit y<sub>i</sub> ou y<sub>j</sub> et 2/(j-i+1).
</p>

<p>
Ainsi nous obtenons :
</p>

<p>
\[\begin{array}{rcl}
  E(X) & =& \sum_{i=1}^{n-1} \sum_{j =i+1}^n E(X_{ij}) \\
  &=& \sum_{i=1}^{n-1} \sum_{j =i+1}^n \frac{2}{j-i+1}\\
  &=& \sum_{i=1}^{n-1} \sum_{k=2}^{n-i+1} \frac{2}{k}\\
  &=&  \sum_{k=2}^{n-i+1} \sum_{i=2}^{n-1} \frac{2}{k}\\
  &=& \sum_{k=2}^n(n+1-k)\frac{2}{k}\\
  &=& \left((n+1)\sum_{k=2}^n \frac{2}{k}\right) -2(n-1)\\
  &=& (2n+2)\sum_{k=1}^n\frac{1}{n} -4n
  \end{array}\]
</p>

<p>
\(\sum_{k=1}^n\frac{1}{n}\) est le nombre harmonique H(n) et \(H(n) = ln(n)
  +\Theta(1)\). Ainsi \(E(X) = 2n ln(n) + \Theta(n)\)
</p>
</div>
</div>
</div></div></div>
</body>
</html>
